AWSTemplateFormatVersion: '2010-09-09'
Description: "Free-tier EC2 backend for TickTock Tasks with automatic TLS via Caddy and Route53 DNS"

Parameters:
  DomainName:
    Type: String
    Description: "Base domain for your site (must be in the provided HostedZone). Example: ticktocktasks.com"
  ApiSubdomain:
    Type: String
    Default: api
    Description: "Subdomain for the backend (api -> api.<DomainName>)"
  HostedZoneId:
    Type: String
    Description: "Route53 Hosted Zone ID for the DomainName"
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: "VPC where the instance and security group will be created"
  SubnetId:
    Type: AWS::EC2::Subnet::Id
    Description: "Public subnet for the instance (must provide internet access and auto-assign public IP)"
  InstanceType:
    Type: String
    Default: t2.micro
    AllowedValues: [t2.micro, t3.micro]
    Description: "EC2 instance type (free-tier eligible: t2.micro)"
  KeyName:
    Type: String
    Default: ''
    Description: "Optional SSH key pair name to access the instance (leave empty to skip)"
  RepoUrl:
    Type: String
    Default: https://github.com/example/Todo_App.git
    Description: "Git repository URL containing this project. Must be accessible by the instance."
  AllowedOrigins:
    Type: String
    Default: https://ticktocktasks.com,https://www.ticktocktasks.com
    Description: "Comma-separated list of allowed frontend origins for CORS (e.g., your CloudFront domain and custom domain)"
  CreateApiDnsRecord:
    Type: String
    AllowedValues: ['true','false']
    Default: 'true'
    Description: "Whether to create the api.<DomainName> Route53 A record. Set 'false' to reuse existing DNS."
  LatestAmi:
    Type: 'AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>'
    Default: '/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-6.1-x86_64'
    Description: "Latest Amazon Linux 2023 AMI via SSM parameter"

Mappings:
  RegionMap:
    us-east-1:
      Ami: ami-05576a079321f21f8
    us-east-2:
      Ami: ami-08fb2ae774d2f6c48
    us-west-2:
      Ami: ami-0f3a42250e0e530d1
    eu-west-1:
      Ami: ami-089950bc622d39ed8

Conditions:
  HasKey: !Not [ !Equals [ !Ref KeyName, '' ] ]
  CreateApiDns: !Equals [ !Ref CreateApiDnsRecord, 'true' ]

Resources:
  BackendSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: "Allow HTTP/HTTPS"
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 8080
          ToPort: 8080
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 8443
          ToPort: 8443
          CidrIp: 0.0.0.0/0
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Project
          Value: TickTockTasks

  BackendRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
      Policies:
        - PolicyName: TickTockBackendCloudWatchLogs
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - logs:DescribeLogStreams
                  - logs:DescribeLogGroups
                Resource: '*'

  BackendInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles: [ !Ref BackendRole ]

  BackendLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/TickTock/Backend-${DomainName}'
      RetentionInDays: 14
      Tags:
        - Key: Project
          Value: TickTockTasks

  BackendEc2:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Ref LatestAmi
      InstanceType: !Ref InstanceType
      IamInstanceProfile: !Ref BackendInstanceProfile
      KeyName: !If [HasKey, !Ref KeyName, !Ref AWS::NoValue]
      NetworkInterfaces:
        - DeviceIndex: 0
          AssociatePublicIpAddress: true
          SubnetId: !Ref SubnetId
          GroupSet: [ !Ref BackendSecurityGroup ]
      Tags:
        - Key: Name
          Value: TickTockTasks-Backend
        - Key: Project
          Value: TickTockTasks
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -xe
          # Install docker, compose plugin, caddy, git, jq
          (dnf update -y || yum update -y) || true
          (dnf install -y docker docker-compose-plugin git jq || yum install -y docker git jq) || true
          # Fallback for compose if plugin missing
          if ! command -v docker-compose >/dev/null 2>&1; then
            if ! docker compose version >/dev/null 2>&1; then
              curl -L "https://github.com/docker/compose/releases/download/v2.27.0/docker-compose-linux-x86_64" -o /usr/local/bin/docker-compose && chmod +x /usr/local/bin/docker-compose || true
            fi
          fi
          # Caddy for automatic TLS (robust install across distros)
          if command -v dnf >/dev/null 2>&1; then
            ELVER=$(awk -F= '/^VERSION_ID/{print $2}' /etc/os-release | tr -d '"' | cut -d. -f1)
            [ -z "$ELVER" ] && ELVER=9
            (dnf install -y dnf-plugins-core || true)
            (dnf config-manager --add-repo "https://dl.cloudsmith.io/public/caddy/stable/rpm/el/$ELVER.repo" || true)
            (dnf install -y caddy || true)
          else
            ELVER=$(awk -F= '/^VERSION_ID/{print $2}' /etc/os-release | tr -d '"' | cut -d. -f1)
            [ -z "$ELVER" ] && ELVER=7
            (yum install -y yum-utils || true)
            (yum-config-manager --add-repo "https://dl.cloudsmith.io/public/caddy/stable/rpm/el/$ELVER.repo" || true)
            (yum install -y caddy || true)
          fi
          systemctl enable --now docker
          # Ensure systemd Caddy is not running; we'll use dockerized Caddy
          systemctl disable --now caddy || true

          # Clone repo
          mkdir -p /opt/ticktock
          if [ ! -d /opt/ticktock/.git ]; then
            git clone "${RepoUrl}" /opt/ticktock || true
          fi
          cd /opt/ticktock
          chmod +x ./backend-up.sh || true

          # Configure Docker logging and containerized Caddy reverse proxy via override before first start
          cat > /opt/ticktock/docker-compose.override.yml <<OVR
          version: '3.8'
          services:
            backend:
              logging:
                driver: awslogs
                options:
                  awslogs-region: ${AWS::Region}
                  awslogs-group: /TickTock/Backend-${DomainName}
                  awslogs-create-group: "true"
            caddy:
              image: caddy:2
              container_name: ticktock-caddy
              restart: unless-stopped
              ports:
                - "80:80"
                - "443:443"
              volumes:
                - /opt/ticktock/Caddyfile:/etc/caddy/Caddyfile
              depends_on:
                - backend
              healthcheck:
                test: ["CMD-SHELL", "wget -qO- --header='Host: ${ApiSubdomain}.${DomainName}' http://127.0.0.1/healthz >/dev/null || exit 1"]
                interval: 30s
                timeout: 5s
                retries: 3
                start_period: 30s
              logging:
                driver: awslogs
                options:
                  awslogs-region: ${AWS::Region}
                  awslogs-group: /TickTock/Backend-${DomainName}
                  awslogs-create-group: "true"
            autoheal:
              image: willfarrell/autoheal
              container_name: ticktock-autoheal
              restart: unless-stopped
              environment:
                - AUTOHEAL_CONTAINER_LABEL=all
                - AUTOHEAL_INTERVAL=10
              volumes:
                - /var/run/docker.sock:/var/run/docker.sock
          OVR

          # Prepare env and start backend (write .env with first origin), then widen to all AllowedOrigins
          FRONT_ORIGIN="$(echo "${AllowedOrigins}" | cut -d',' -f1)"
          export CORS_ORIGIN="${AllowedOrigins}"
          ./backend-up.sh "$FRONT_ORIGIN" || true
          if [ -f .env ]; then
            sed -i "s|^CORS_ORIGIN=.*|CORS_ORIGIN=${AllowedOrigins}|" .env || true
            if grep -q '^REDIRECT_HTTP_TO_HTTPS=' .env; then
              sed -i 's#^REDIRECT_HTTP_TO_HTTPS=.*#REDIRECT_HTTP_TO_HTTPS=false#' .env || true
            else
              echo 'REDIRECT_HTTP_TO_HTTPS=false' >> .env
            fi
          fi

          # Write Caddyfile before first start so proxy is ready immediately
          cat >/opt/ticktock/Caddyfile <<CFG
          ${ApiSubdomain}.${DomainName} {
            encode gzip
            reverse_proxy http://backend:8080
          }
          CFG

          # Start containers
          # Remove stray containers to avoid name conflicts with compose
          docker rm -f ticktock-caddy ticktock-autoheal 2>/dev/null || true
          if command -v docker-compose >/dev/null 2>&1; then
            docker-compose up -d || true
          else
            docker compose up -d || true
          fi

          # Configure Caddyfile for containerized Caddy reverse proxy
          cat >/opt/ticktock/Caddyfile <<CFG
          ${ApiSubdomain}.${DomainName} {
            encode gzip
            reverse_proxy http://backend:8080
          }
          CFG
          # Ensure systemd Caddy is stopped (free ports 80/443)
          systemctl stop caddy || true
          # Restart containers to pick up caddy service/config
          # Remove stray containers to avoid name conflicts with compose
          docker rm -f ticktock-caddy ticktock-autoheal 2>/dev/null || true
          if command -v docker-compose >/dev/null 2>&1; then
            docker-compose up -d || true
          else
            docker compose up -d || true
          fi
          # Wait for Caddy to listen on 80/443
          for i in $(seq 1 60); do
            if ss -ltn 2>/dev/null | grep -E 'LISTEN.+:(80|443)'; then
              break
            fi
            sleep 2
          done

  ApiRecord:
    Condition: CreateApiDns
    Type: AWS::Route53::RecordSet
    DependsOn: BackendEc2
    Properties:
      HostedZoneId: !Ref HostedZoneId
      Name: !Sub '${ApiSubdomain}.${DomainName}'
      Type: A
      TTL: '60'
      ResourceRecords:
        - !GetAtt BackendEc2.PublicIp

Outputs:
  InstanceId:
    Description: EC2 instance ID
    Value: !Ref BackendEc2
  PublicIp:
    Description: EC2 public IP
    Value: !GetAtt BackendEc2.PublicIp
  ApiDomainName:
    Description: Backend API domain name
    Value: !Sub '${ApiSubdomain}.${DomainName}'
  BackendEndpoint:
    Description: HTTPS endpoint for backend
    Value: !Sub 'https://${ApiSubdomain}.${DomainName}'
