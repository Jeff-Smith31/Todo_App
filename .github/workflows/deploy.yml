name: Deploy Frontend and Backend

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  # Frontend (must be us-east-1 for CloudFront ACM)
  FRONTEND_REGION: ${{ vars.FRONTEND_REGION || 'us-east-1' }}
  FRONTEND_STACK_NAME: ${{ vars.FRONTEND_STACK_NAME || 'ttt-frontend' }}
  DOMAIN_NAME: ${{ vars.DOMAIN_NAME || 'ticktocktasks.com' }}
  HOSTED_ZONE_ID: ${{ vars.HOSTED_ZONE_ID || 'Z08471201NA2PN7ERBIB7' }}
  INCLUDE_WWW: ${{ vars.INCLUDE_WWW || 'true' }}
  INCLUDE_APP_SUBDOMAIN: ${{ vars.INCLUDE_APP_SUBDOMAIN || 'false' }}
  APP_SUBDOMAIN: ${{ vars.APP_SUBDOMAIN || 'app' }}
  # Optional explicit resource reuse overrides
  EXISTING_BUCKET_NAME: ${{ vars.EXISTING_BUCKET_NAME || '' }}
  EXISTING_CERT_ARN: ${{ vars.EXISTING_CERT_ARN || '' }}

  # Backend
  BACKEND_REGION: ${{ vars.BACKEND_REGION || 'us-east-1' }}
  BACKEND_STACK_NAME: ${{ vars.BACKEND_STACK_NAME || 'ttt-backend' }}
  VPC_ID: ${{ vars.VPC_ID }}
  SUBNET_ID: ${{ vars.SUBNET_ID }}
  API_SUBDOMAIN: ${{ vars.API_SUBDOMAIN || 'api' }}
  BACKEND_OVERRIDE_URL: ${{ vars.BACKEND_OVERRIDE_URL || '' }}
  USE_RELATIVE_API: ${{ vars.USE_RELATIVE_API || '' }}
  USE_CLOUDFRONT: ${{ vars.USE_CLOUDFRONT || 'true' }}

  # DNS safeguard (ensure Hosted Zone points correctly when not using CloudFront)
  FIX_DNS_TO_EC2: ${{ vars.FIX_DNS_TO_EC2 || 'true' }}
  EC2_PUBLIC_IP: ${{ vars.EC2_PUBLIC_IP || '' }}
  # DNS enforcement: fail CI if CloudFront is still configured when USE_CLOUDFRONT=false
  DNS_ENFORCE_STRICT: ${{ vars.DNS_ENFORCE_STRICT || 'true' }}

jobs:
  deploy:
    name: Deploy stacks and link frontend
    runs-on: ubuntu-latest
    permissions:
      id-token: write    # for AWS OIDC federation
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (us-east-1)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.FRONTEND_REGION }}

      - name: Resolve Domain and Hosted Zone (fallbacks)
        run: |
          set -e
          # Ensure jq is installed for JSON parsing
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y && sudo apt-get install -y jq
          fi
          # If DOMAIN_NAME/HOSTED_ZONE_ID are not provided as repo variables, try to infer them from the existing frontend stack or Route53
          MISSING_DOMAIN="${DOMAIN_NAME:-}"
          MISSING_ZONE="${HOSTED_ZONE_ID:-}"
          FRONT_STACK="${FRONTEND_STACK_NAME}"

          if [ -z "$MISSING_DOMAIN" ] || [ -z "$MISSING_ZONE" ]; then
            if aws cloudformation describe-stacks --region "$FRONTEND_REGION" --stack-name "$FRONT_STACK" >/dev/null 2>&1; then
              DN=$(aws cloudformation describe-stacks \
                --region "$FRONTEND_REGION" \
                --stack-name "$FRONT_STACK" \
                --query "Stacks[0].Parameters[?ParameterKey=='DomainName'].ParameterValue | [0]" \
                --output text)
              HZ=$(aws cloudformation describe-stacks \
                --region "$FRONTEND_REGION" \
                --stack-name "$FRONT_STACK" \
                --query "Stacks[0].Parameters[?ParameterKey=='HostedZoneId'].ParameterValue | [0]" \
                --output text)
              if [ -z "$MISSING_DOMAIN" ] && [ -n "$DN" ] && [ "$DN" != "None" ]; then
                echo "DOMAIN_NAME=$DN" >> "$GITHUB_ENV"
                MISSING_DOMAIN="$DN"
              fi
              if [ -z "$MISSING_ZONE" ] && [ -n "$HZ" ] && [ "$HZ" != "None" ]; then
                echo "HOSTED_ZONE_ID=$HZ" >> "$GITHUB_ENV"
                MISSING_ZONE="$HZ"
              fi

              # If still missing DomainName, try derive from BucketName output (<DomainName>-site)
              if [ -z "$MISSING_DOMAIN" ]; then
                BUCKET=$(aws cloudformation describe-stacks \
                  --region "$FRONTEND_REGION" \
                  --stack-name "$FRONT_STACK" \
                  --query "Stacks[0].Outputs[?OutputKey=='BucketName'].OutputValue | [0]" \
                  --output text)
                if [ -n "$BUCKET" ] && [ "$BUCKET" != "None" ]; then
                  if [ "${BUCKET##*-}" = "site" ]; then
                    DN2="${BUCKET%-site}"
                    echo "DOMAIN_NAME=$DN2" >> "$GITHUB_ENV"
                    MISSING_DOMAIN="$DN2"
                  fi
                fi
              fi
            fi

            # If we have DomainName but not HostedZoneId, look it up in Route53
            if [ -z "$MISSING_ZONE" ] && [ -n "$MISSING_DOMAIN" ]; then
              HZ2=$(aws route53 list-hosted-zones-by-name --dns-name "${MISSING_DOMAIN}." --query "HostedZones[0].Id" --output text 2>/dev/null || true)
              HZ2=${HZ2#/hostedzone/}
              if [ -n "$HZ2" ] && [ "$HZ2" != "None" ]; then
                echo "HOSTED_ZONE_ID=$HZ2" >> "$GITHUB_ENV"
                MISSING_ZONE="$HZ2"
              fi
            fi
          fi

          # If still missing both or one of them, try to infer from Route53 hosted zones
          if [ -z "$MISSING_DOMAIN" ] || [ -z "$MISSING_ZONE" ]; then
            # List public hosted zones
            ZONES_JSON=$(aws route53 list-hosted-zones --query "HostedZones[?Config.PrivateZone==\`false\`]")
            COUNT=$(echo "$ZONES_JSON" | jq 'length')
            if [ "$COUNT" -gt 0 ]; then
              # Choose the first zone; if only one exists, it's unambiguous
              Z_NAME=$(echo "$ZONES_JSON" | jq -r '.[0].Name' | sed 's/\.$//')
              Z_ID=$(echo "$ZONES_JSON" | jq -r '.[0].Id' | sed 's#.*/##')
              if [ -z "$MISSING_DOMAIN" ] && [ -n "$Z_NAME" ] && [ "$Z_NAME" != "null" ]; then
                echo "DOMAIN_NAME=$Z_NAME" >> "$GITHUB_ENV"
                MISSING_DOMAIN="$Z_NAME"
              fi
              if [ -z "$MISSING_ZONE" ] && [ -n "$Z_ID" ] && [ "$Z_ID" != "null" ]; then
                echo "HOSTED_ZONE_ID=$Z_ID" >> "$GITHUB_ENV"
                MISSING_ZONE="$Z_ID"
              fi
              echo "Route53 fallback used. Chosen zone: $Z_NAME ($Z_ID)" >> $GITHUB_STEP_SUMMARY
              if [ "$COUNT" -gt 1 ]; then
                echo "Warning: Multiple public hosted zones detected; selected the first. Set repo Variables DOMAIN_NAME and HOSTED_ZONE_ID to override." >> $GITHUB_STEP_SUMMARY
              fi
            fi
          fi

          # Ensure INCLUDE_WWW default if unset
          if [ -z "${INCLUDE_WWW:-}" ]; then echo "INCLUDE_WWW=true" >> "$GITHUB_ENV"; fi

          # Summarize resolution
          echo "Resolved DOMAIN_NAME=${MISSING_DOMAIN:-<unset>}" >> $GITHUB_STEP_SUMMARY
          echo "Resolved HOSTED_ZONE_ID=${MISSING_ZONE:-<unset>}" >> $GITHUB_STEP_SUMMARY

      - name: Resolve VPC and Subnet (fallbacks)
        run: |
          set -e
          # If provided explicitly, keep them
          if [ -n "${VPC_ID:-}" ] && [ -n "${SUBNET_ID:-}" ]; then
            echo "Using provided VPC_ID and SUBNET_ID" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi

          # Find default VPC in the backend region
          VPC=$(aws ec2 describe-vpcs \
            --region "${BACKEND_REGION}" \
            --filters "Name=isDefault,Values=true" \
            --query "Vpcs[0].VpcId" \
            --output text 2>/dev/null || true)

          # Fallback to the first VPC if no default VPC
          if [ -z "$VPC" ] || [ "$VPC" = "None" ]; then
            VPC=$(aws ec2 describe-vpcs \
              --region "${BACKEND_REGION}" \
              --query "Vpcs[0].VpcId" \
              --output text 2>/dev/null || true)
          fi

          if [ -n "$VPC" ] && [ "$VPC" != "None" ]; then
            echo "VPC_ID=$VPC" >> "$GITHUB_ENV"
          fi

          SUB=""
          if [ -n "$VPC" ] && [ "$VPC" != "None" ]; then
            # Prefer default subnets for AZs within the VPC
            SUB=$(aws ec2 describe-subnets \
              --region "${BACKEND_REGION}" \
              --filters "Name=vpc-id,Values=$VPC" \
              --query "Subnets[?DefaultForAz==\`true\`][0].SubnetId" \
              --output text 2>/dev/null || true)

            # If none, try to find a subnet with MapPublicIpOnLaunch=true
            if [ -z "$SUB" ] || [ "$SUB" = "None" ]; then
              IDS=$(aws ec2 describe-subnets \
                --region "${BACKEND_REGION}" \
                --filters "Name=vpc-id,Values=$VPC" \
                --query "Subnets[].SubnetId" \
                --output text 2>/dev/null || true)
              for S in $IDS; do
                MPL=$(aws ec2 describe-subnet-attribute \
                  --region "${BACKEND_REGION}" \
                  --subnet-id "$S" \
                  --attribute mapPublicIpOnLaunch \
                  --query "MapPublicIpOnLaunch.Value" \
                  --output text 2>/dev/null || echo "false")
                if [ "$MPL" = "True" ] || [ "$MPL" = "true" ]; then
                  SUB="$S"; break;
                fi
              done
            fi

            # Fallback to first subnet in the VPC
            if [ -z "$SUB" ] || [ "$SUB" = "None" ]; then
              SUB=$(aws ec2 describe-subnets \
                --region "${BACKEND_REGION}" \
                --filters "Name=vpc-id,Values=$VPC" \
                --query "Subnets[0].SubnetId" \
                --output text 2>/dev/null || true)
            fi

            if [ -n "$SUB" ] && [ "$SUB" != "None" ]; then
              echo "SUBNET_ID=$SUB" >> "$GITHUB_ENV"
            fi
          fi

          echo "Resolved VPC_ID=${VPC:-<unset>}" >> $GITHUB_STEP_SUMMARY
          echo "Resolved SUBNET_ID=${SUB:-<unset>}" >> $GITHUB_STEP_SUMMARY

      - name: Validate required variables
        run: |
          set -e
          for v in DOMAIN_NAME HOSTED_ZONE_ID VPC_ID SUBNET_ID; do
            if [ -z "${!v}" ]; then echo "Missing required repo variable: $v"; exit 2; fi
          done



      - name: Assert Route53 DNS points to EC2 (not CloudFront)
        if: ${{ env.USE_CLOUDFRONT == 'false' }}
        run: |
          set -e
          ZID="${HOSTED_ZONE_ID}"
          DN="${DOMAIN_NAME}"
          INC_WWW="${INCLUDE_WWW}"
          FIX="${FIX_DNS_TO_EC2}"
          EC2IP="${EC2_PUBLIC_IP}"
          echo "Checking Route53 records for ${DN} in zone ${ZID} (CloudFront aliases are not allowed when USE_CLOUDFRONT=false)" >> $GITHUB_STEP_SUMMARY
          # Ensure jq installed
          if ! command -v jq >/dev/null 2>&1; then sudo apt-get update -y && sudo apt-get install -y jq >/dev/null; fi
          JSON=$(aws route53 list-resource-record-sets --hosted-zone-id "$ZID")
          check_name(){
            local NAME="$1"
            local CF=false
            local REC=$(echo "$JSON" | jq -r --arg N "${NAME}." '.ResourceRecordSets[] | select(.Name==$N and (.Type=="A" or .Type=="CNAME")) | if .AliasTarget then .AliasTarget.DNSName else (if .ResourceRecords then .ResourceRecords[0].Value else "" end) end')
            if echo "$REC" | grep -qi 'cloudfront\.net'; then CF=true; fi
            echo "${NAME}: target=${REC:-<none>}" >> $GITHUB_STEP_SUMMARY
            if $CF; then echo "Warning: ${NAME} points to CloudFront (cloudfront.net)." >> $GITHUB_STEP_SUMMARY; fi
            $CF && return 0 || return 1
          }
          CF_APEX=false; CF_WWW=false
          if check_name "$DN"; then CF_APEX=true; fi
          if [ "$INC_WWW" = "true" ]; then if check_name "www.$DN"; then CF_WWW=true; fi; fi
          NEED_FIX=false
          if $CF_APEX || $CF_WWW; then NEED_FIX=true; fi
          if ! $NEED_FIX; then echo "DNS OK: no CloudFront aliases detected." >> $GITHUB_STEP_SUMMARY; exit 0; fi
          if [ "$FIX" != "true" ]; then
            echo "Action required: Update Route53 A record(s) to point to your EC2 IP. Set FIX_DNS_TO_EC2=true and EC2_PUBLIC_IP to auto-fix in this workflow, or run scripts/route53-switch-to-ec2.sh locally." >> $GITHUB_STEP_SUMMARY
            if [ "${DNS_ENFORCE_STRICT}" = "true" ]; then
              echo "Failing job due to DNS pointing to CloudFront while USE_CLOUDFRONT=false (DNS_ENFORCE_STRICT=true)." >> $GITHUB_STEP_SUMMARY
              exit 1
            else
              exit 0
            fi
          fi
          if [ -z "$EC2IP" ]; then
            echo "FIX_DNS_TO_EC2=true but EC2_PUBLIC_IP is empty. Attempting to auto-resolve EC2 public IP from backend stack..." >> $GITHUB_STEP_SUMMARY
            # Try common backend stack outputs first
            IP_OUT=$(aws cloudformation describe-stacks \
              --region "${BACKEND_REGION}" \
              --stack-name "${BACKEND_STACK_NAME}" \
              --query "Stacks[0].Outputs[?OutputKey=='InstancePublicIp' || OutputKey=='PublicIp'].OutputValue | [0]" \
              --output text 2>/dev/null || echo None)
            if [ -n "$IP_OUT" ] && [ "$IP_OUT" != "None" ]; then
              EC2IP="$IP_OUT"
            else
              # Resolve InstanceId then describe its PublicIpAddress
              IID=$(aws cloudformation describe-stacks \
                --region "${BACKEND_REGION}" \
                --stack-name "${BACKEND_STACK_NAME}" \
                --query "Stacks[0].Outputs[?OutputKey=='InstanceId'].OutputValue | [0]" \
                --output text 2>/dev/null || echo None)
              if [ -n "$IID" ] && [ "$IID" != "None" ]; then
                EC2IP=$(aws ec2 describe-instances \
                  --region "${BACKEND_REGION}" \
                  --instance-ids "$IID" \
                  --query "Reservations[0].Instances[0].PublicIpAddress" \
                  --output text 2>/dev/null || echo "")
              fi
            fi
          fi
          if [ -z "$EC2IP" ]; then echo "Auto-resolution failed; provide EC2_PUBLIC_IP or ensure backend stack outputs InstancePublicIp/InstanceId. Failing." >> $GITHUB_STEP_SUMMARY; exit 1; fi
          echo "Applying UPSERT to point ${DN} (and www if enabled) to ${EC2IP}" >> $GITHUB_STEP_SUMMARY
          CHANGES=$(jq -cn --arg dom "$DN" --arg ip "$EC2IP" --arg inc "$INC_WWW" '
            ([{Action:"UPSERT",ResourceRecordSet:{Name:$dom,Type:"A",TTL:60,ResourceRecords:[{Value:$ip}]}}]
             + (if $inc=="true" then [{Action:"UPSERT",ResourceRecordSet:{Name:("www."+$dom),Type:"A",TTL:60,ResourceRecords:[{Value:$ip}]}}] else [] end))')
          aws route53 change-resource-record-sets --hosted-zone-id "$ZID" --change-batch "{\"Changes\":$(echo "$CHANGES" | jq -c .)}" >/dev/null
          echo "Submitted DNS changes. Propagation may take a few minutes." >> $GITHUB_STEP_SUMMARY

      - name: Detect existing frontend resources (bucket, cert, DNS)
        run: |
          set -e
          # Allow explicit override via repo variables
          if [ -n "${EXISTING_BUCKET_NAME:-}" ]; then
            echo "FRONT_EXISTING_BUCKET=${EXISTING_BUCKET_NAME}" >> "$GITHUB_ENV"
            echo "Reusing existing bucket (override): ${EXISTING_BUCKET_NAME}" >> $GITHUB_STEP_SUMMARY
          else
            BUCKET_NAME="${DOMAIN_NAME}-site"
            if aws s3api head-bucket --bucket "$BUCKET_NAME" >/dev/null 2>&1; then
              echo "FRONT_EXISTING_BUCKET=$BUCKET_NAME" >> "$GITHUB_ENV"
              echo "Reusing existing bucket: $BUCKET_NAME" >> $GITHUB_STEP_SUMMARY
            fi
          fi

          if [ -n "${EXISTING_CERT_ARN:-}" ]; then
            echo "FRONT_EXISTING_CERT_ARN=${EXISTING_CERT_ARN}" >> "$GITHUB_ENV"
            echo "Reusing existing ACM cert (override): ${EXISTING_CERT_ARN}" >> $GITHUB_STEP_SUMMARY
          else
            CERT1=$(aws acm list-certificates \
              --region "${FRONTEND_REGION}" \
              --certificate-statuses ISSUED \
              --query "CertificateSummaryList[?DomainName=='${DOMAIN_NAME}'].CertificateArn | [0]" \
              --output text 2>/dev/null || true)
            WILDC="*.${DOMAIN_NAME}"
            CERT2=$(aws acm list-certificates \
              --region "${FRONTEND_REGION}" \
              --certificate-statuses ISSUED \
              --query "CertificateSummaryList[?DomainName=='${WILDC}'].CertificateArn | [0]" \
              --output text 2>/dev/null || true)
            CERT_ARN="${CERT1}"
            if [ -z "$CERT_ARN" ] || [ "$CERT_ARN" = "None" ]; then CERT_ARN="$CERT2"; fi
            if [ -n "$CERT_ARN" ] && [ "$CERT_ARN" != "None" ]; then
              echo "FRONT_EXISTING_CERT_ARN=$CERT_ARN" >> "$GITHUB_ENV"
              echo "Reusing existing ACM cert: $CERT_ARN" >> $GITHUB_STEP_SUMMARY
            fi
          fi

          APEX_A=$(aws route53 list-resource-record-sets \
            --hosted-zone-id "${HOSTED_ZONE_ID}" \
            --query "ResourceRecordSets[?Name=='${DOMAIN_NAME}.'] | [?Type=='A' || Type=='AAAA'] | [0].Type" \
            --output text 2>/dev/null || true)
          if [ -n "$APEX_A" ] && [ "$APEX_A" != "None" ]; then
            echo "CREATE_DNS_RECORDS=false" >> "$GITHUB_ENV"
            echo "Skipping DNS record creation (records already exist for ${DOMAIN_NAME})." >> $GITHUB_STEP_SUMMARY
          else
            echo "CREATE_DNS_RECORDS=true" >> "$GITHUB_ENV"
          fi

      - name: Decide SkipAliases based on ACM certificate coverage
        if: ${{ env.USE_CLOUDFRONT == 'true' }}
        run: |
          set -e
          SA="false"
          # Only evaluate when reusing an existing ACM certificate
          if [ -n "${FRONT_EXISTING_CERT_ARN:-}" ]; then
            # Ensure jq is installed
            if ! command -v jq >/dev/null 2>&1; then
              sudo apt-get update -y && sudo apt-get install -y jq
            fi
            CERT_ARN="${FRONT_EXISTING_CERT_ARN}"
            echo "Evaluating ACM cert coverage for aliases using ${CERT_ARN}" >> $GITHUB_STEP_SUMMARY
            JSON=$(aws acm describe-certificate --region "${FRONTEND_REGION}" --certificate-arn "$CERT_ARN" --output json || echo '')
            if [ -z "$JSON" ]; then
              echo "Warning: Unable to describe ACM certificate; will not skip aliases." >> $GITHUB_STEP_SUMMARY
            else
              CN=$(echo "$JSON" | jq -r '.Certificate.DomainName // empty')
              SANS=$(echo "$JSON" | jq -r '.Certificate.SubjectAlternativeNames[]?')
              ALL=$(printf "%s\n%s\n" "$CN" "$SANS" | awk 'NF' | sort -u)
              APEX="${DOMAIN_NAME}"
              REQS="$APEX"
              if [ "${INCLUDE_WWW}" = "true" ]; then REQS="$REQS www.${DOMAIN_NAME}"; fi
              WILDC="*.${DOMAIN_NAME}"
              # Helper to test coverage for one name
              covered(){
                local N="$1"
                # apex must be explicitly present
                if [ "$N" = "$APEX" ]; then echo "$ALL" | grep -Fxq "$N" && return 0 || return 1; fi
                # subdomains covered by explicit name or wildcard
                echo "$ALL" | grep -Fxq "$N" && return 0
                echo "$ALL" | grep -Fxq "$WILDC" && return 0
                return 1
              }
              for N in $REQS; do
                if ! covered "$N"; then
                  echo "Certificate does not cover required name: $N" >> $GITHUB_STEP_SUMMARY
                  SA="true"
                fi
              done
            fi
          fi
          if [ "$SA" = "true" ]; then
            echo "SKIP_ALIASES=true" >> "$GITHUB_ENV"
            echo "CREATE_DNS_RECORDS=false" >> "$GITHUB_ENV"
            echo "Outcome: Will deploy CloudFront WITHOUT Aliases and will NOT create DNS records to avoid mismatch." >> $GITHUB_STEP_SUMMARY
          else
            echo "SKIP_ALIASES=false" >> "$GITHUB_ENV"
          fi

      - name: Deploy frontend stack (S3 + CloudFront + ACM + Route53)
        if: ${{ env.USE_CLOUDFRONT == 'true' }}
        run: |
          set +e
          aws cloudformation deploy \
            --region "${FRONTEND_REGION}" \
            --stack-name "${FRONTEND_STACK_NAME}" \
            --template-file infra/frontend/template.yaml \
            --parameter-overrides \
              DomainName="${DOMAIN_NAME}" \
              HostedZoneId="${HOSTED_ZONE_ID}" \
              IncludeWww="${INCLUDE_WWW}" \
              IncludeAppSubdomain="${INCLUDE_APP_SUBDOMAIN}" \
              AppSubdomain="${APP_SUBDOMAIN}" \
              ExistingBucketName="${FRONT_EXISTING_BUCKET:-}" \
              ExistingCertificateArn="${FRONT_EXISTING_CERT_ARN:-}" \
              CreateDnsRecords="${CREATE_DNS_RECORDS:-true}" \
              SkipAliases="${SKIP_ALIASES:-false}" \
            --capabilities CAPABILITY_NAMED_IAM
          RC=$?
          set -e
          if [ $RC -ne 0 ]; then
            echo "Frontend stack deploy failed (rc=$RC). Will attempt to reuse an existing CloudFront distribution by alias (CNAME) and continue." >> $GITHUB_STEP_SUMMARY
          fi
          exit 0

      - name: Get frontend outputs
        if: ${{ env.USE_CLOUDFRONT == 'true' }}
        id: front
        run: |
          set -e
          # Try to read outputs from the frontend stack
          BUCKET=$(aws cloudformation describe-stacks \
            --region "${FRONTEND_REGION}" \
            --stack-name "${FRONTEND_STACK_NAME}" \
            --query "Stacks[0].Outputs[?OutputKey=='BucketName'].OutputValue | [0]" \
            --output text 2>/dev/null || echo None)
          DIST_ID=$(aws cloudformation describe-stacks \
            --region "${FRONTEND_REGION}" \
            --stack-name "${FRONTEND_STACK_NAME}" \
            --query "Stacks[0].Outputs[?OutputKey=='DistributionId'].OutputValue | [0]" \
            --output text 2>/dev/null || echo None)
          CF_DOMAIN=$(aws cloudformation describe-stacks \
            --region "${FRONTEND_REGION}" \
            --stack-name "${FRONTEND_STACK_NAME}" \
            --query "Stacks[0].Outputs[?OutputKey=='DistributionDomainName'].OutputValue | [0]" \
            --output text 2>/dev/null || echo None)

          # If a distribution exists but the bucket output is missing, derive the bucket from the distribution's default origin
          if { [ -z "$BUCKET" ] || [ "$BUCKET" = "None" ]; } && { [ -n "$DIST_ID" ] && [ "$DIST_ID" != "None" ]; }; then
            # Ensure jq is installed
            if ! command -v jq >/dev/null 2>&1; then sudo apt-get update -y && sudo apt-get install -y jq; fi
            DIST_JSON=$(aws cloudfront get-distribution --id "$DIST_ID" --output json 2>/dev/null || true)
            if [ -n "$DIST_JSON" ]; then
              TOID=$(echo "$DIST_JSON" | jq -r '.Distribution.DistributionConfig.DefaultCacheBehavior.TargetOriginId // empty')
              ODOM=$(echo "$DIST_JSON" | jq -r ".Distribution.DistributionConfig.Origins.Items[] | select(.Id==\"${TOID}\").DomainName // empty")
              if [ -n "$ODOM" ]; then
                case "$ODOM" in
                  *.s3.amazonaws.com) BUCKET="${ODOM%%.s3.amazonaws.com}" ;;
                  *.s3.*.amazonaws.com) BUCKET="${ODOM%%.s3.*.amazonaws.com}" ;;
                  *.s3-website-*.amazonaws.com) BUCKET="${ODOM%%.s3-website-*.amazonaws.com}" ;;
                  *) BUCKET="$ODOM" ;;
                esac
                BUCKET=$(echo "$BUCKET" | sed -E 's/\.s3(\.[a-z0-9-]+)?\.amazonaws\.com$//')
              fi
            fi
          fi

          # Fallbacks if stack outputs and distribution bucket could not be resolved
          if [ -z "$BUCKET" ] || [ "$BUCKET" = "None" ]; then
            if [ -n "${FRONT_EXISTING_BUCKET:-}" ]; then
              BUCKET="${FRONT_EXISTING_BUCKET}"
            else
              # Default naming convention (only create if not using an existing distribution)
              BUCKET="${DOMAIN_NAME}-site"
              # Create bucket if it doesn't exist (us-east-1 has special rules)
              if ! aws s3api head-bucket --bucket "$BUCKET" >/dev/null 2>&1; then
                if [ "${FRONTEND_REGION}" = "us-east-1" ]; then
                  aws s3api create-bucket --bucket "$BUCKET" >/dev/null
                else
                  aws s3api create-bucket --bucket "$BUCKET" --create-bucket-configuration LocationConstraint="${FRONTEND_REGION}" >/dev/null
                fi
              fi
            fi
          fi

          # Also resolve any existing distribution by alias (CNAME) and its origin bucket
          if ! command -v jq >/dev/null 2>&1; then sudo apt-get update -y && sudo apt-get install -y jq; fi
          ALIAS_DID=$(aws cloudfront list-distributions \
            --query "DistributionList.Items[?Aliases.Items!=null && (contains(Aliases.Items, '${DOMAIN_NAME}') || contains(Aliases.Items, 'www.${DOMAIN_NAME}'))].[Id,DomainName] | [0]" \
            --output text 2>/dev/null || true)
          ALIAS_DIST_ID=""; ALIAS_CF_DOMAIN=""; ALIAS_BUCKET=""
          if [ -n "$ALIAS_DID" ] && [ "$ALIAS_DID" != "None" ]; then
            ALIAS_DIST_ID=$(echo "$ALIAS_DID" | awk '{print $1}')
            ALIAS_CF_DOMAIN=$(echo "$ALIAS_DID" | awk '{print $2}')
            ADJSON=$(aws cloudfront get-distribution --id "$ALIAS_DIST_ID" --output json 2>/dev/null || true)
            if [ -n "$ADJSON" ]; then
              ATOID=$(echo "$ADJSON" | jq -r '.Distribution.DistributionConfig.DefaultCacheBehavior.TargetOriginId // empty')
              AODOM=$(echo "$ADJSON" | jq -r ".Distribution.DistributionConfig.Origins.Items[] | select(.Id==\"${ATOID}\").DomainName // empty")
              if [ -n "$AODOM" ]; then
                case "$AODOM" in
                  *.s3.amazonaws.com) ALIAS_BUCKET="${AODOM%%.s3.amazonaws.com}" ;;
                  *.s3.*.amazonaws.com) ALIAS_BUCKET="${AODOM%%.s3.*.amazonaws.com}" ;;
                  *.s3-website-*.amazonaws.com) ALIAS_BUCKET="${AODOM%%.s3-website-*.amazonaws.com}" ;;
                  *) ALIAS_BUCKET="$AODOM" ;;
                esac
                ALIAS_BUCKET=$(echo "$ALIAS_BUCKET" | sed -E 's/\.s3(\.[a-z0-9-]+)?\.amazonaws\.com$//')
              fi
            fi
          fi

          echo "bucket=$BUCKET" >> "$GITHUB_OUTPUT"
          echo "dist_id=$DIST_ID" >> "$GITHUB_OUTPUT"
          echo "cf_domain=$CF_DOMAIN" >> "$GITHUB_OUTPUT"
          echo "alias_bucket=$ALIAS_BUCKET" >> "$GITHUB_OUTPUT"
          echo "alias_dist_id=$ALIAS_DIST_ID" >> "$GITHUB_OUTPUT"
          echo "alias_cf_domain=$ALIAS_CF_DOMAIN" >> "$GITHUB_OUTPUT"
          if [ -z "$DIST_ID" ] || [ "$DIST_ID" = "None" ]; then
            echo "Warning: Could not resolve a CloudFront distribution. Subsequent invalidation will fail." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Sync site to S3 bucket(s) (proactive origin sync)
        if: ${{ env.USE_CLOUDFRONT == 'true' }}
        run: |
          set -e
          PRIMARY_BUCKET='${{ steps.front.outputs.bucket }}'
          ALIAS_BUCKET='${{ steps.front.outputs.alias_bucket }}'
          if { [ -z "$PRIMARY_BUCKET" ] || [ "$PRIMARY_BUCKET" = "None" ]; } && { [ -z "$ALIAS_BUCKET" ] || [ "$ALIAS_BUCKET" = "None" ]; }; then
            echo "No target bucket resolved"; exit 3; fi

          # Stage entire frontend into a temporary directory so no assets are missed
          SITE_DIR=$(mktemp -d)
          cp -R frontend/website/. "$SITE_DIR/"

          # Build/version id used for cache-busting
          BUILD_ID="${GITHUB_RUN_ID:-0}-${GITHUB_RUN_ATTEMPT:-0}"
          BUILD_TIME="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          INDEX="$SITE_DIR/index.html"
          if [ -f "$INDEX" ]; then
            # Append ?v=BUILD_ID to core assets referenced from index.html
            sed -i "s|\"app.js\"|\"app.js?v=${BUILD_ID}\"|g" "$INDEX" || true
            sed -i "s|\"styles.css\"|\"styles.css?v=${BUILD_ID}\"|g" "$INDEX" || true
            sed -i "s|\"manifest.webmanifest\"|\"manifest.webmanifest?v=${BUILD_ID}\"|g" "$INDEX" || true
            sed -i "s|\"manifest.json\"|\"manifest.json?v=${BUILD_ID}\"|g" "$INDEX" || true
            sed -i "s|\"config.js\"|\"config.js?v=${BUILD_ID}\"|g" "$INDEX" || true
            sed -i "s|\"app-version.js\"|\"app-version.js?v=${BUILD_ID}\"|g" "$INDEX" || true
          fi

          # Create/update version artifacts
          echo "window.APP_VERSION='${BUILD_ID}'; window.APP_BUILD_TIME='${BUILD_TIME}';" > "$SITE_DIR/app-version.js"
          echo "{\"version\":\"${BUILD_ID}\",\"time\":\"${BUILD_TIME}\"}" > "$SITE_DIR/version.json"

          # Ensure config.js exists to avoid SPA 403/404 → index.html MIME trap
          if [ ! -f "$SITE_DIR/config.js" ]; then
            if [ -n "${BACKEND_OVERRIDE_URL:-}" ]; then
              echo "window.RUNTIME_CONFIG=Object.assign({},window.RUNTIME_CONFIG||{},{BACKEND_URL:'${BACKEND_OVERRIDE_URL}'});" > "$SITE_DIR/config.js"
            else
              echo "window.RUNTIME_CONFIG=Object.assign({},window.RUNTIME_CONFIG||{},{BACKEND_URL:''});" > "$SITE_DIR/config.js"
            fi
          fi

          # Bump Service Worker cache name so clients fetch fresh assets
          if [ -f "$SITE_DIR/sw.js" ]; then
            sed -i "s|^const CACHE_NAME = .*|const CACHE_NAME = 'ticktock-cache-${BUILD_ID}';|" "$SITE_DIR/sw.js" || true
          fi

          # Build target bucket list: prefer alias origin bucket first, then stack bucket if different
          TARGETS=""
          if [ -n "$ALIAS_BUCKET" ] && [ "$ALIAS_BUCKET" != "None" ]; then TARGETS="$ALIAS_BUCKET"; fi
          if [ -n "$PRIMARY_BUCKET" ] && [ "$PRIMARY_BUCKET" != "None" ] && [ "$PRIMARY_BUCKET" != "$ALIAS_BUCKET" ]; then TARGETS="$TARGETS $PRIMARY_BUCKET"; fi

          for B in $TARGETS; do
            echo "Syncing static assets to s3://$B (immutable cache) before index.html..."
            aws s3 sync "$SITE_DIR" "s3://$B" --delete --exclude "index.html" --exclude "sw.js" --exclude "config.js" --exclude "app-version.js" --exclude "version.json"

            echo "Uploading critical no-cache files to s3://$B (index.html last)..."
            if [ -f "$SITE_DIR/sw.js" ]; then
              aws s3 cp "$SITE_DIR/sw.js" "s3://$B/sw.js" --cache-control "no-cache, no-store, must-revalidate" --content-type application/javascript
            fi
            aws s3 cp "$SITE_DIR/config.js" "s3://$B/config.js" --cache-control "no-cache, no-store, must-revalidate" --content-type application/javascript
            aws s3 cp "$SITE_DIR/app-version.js" "s3://$B/app-version.js" --cache-control "no-cache, no-store, must-revalidate" --content-type application/javascript
            aws s3 cp "$SITE_DIR/version.json" "s3://$B/version.json" --cache-control "no-cache, no-store, must-revalidate" --content-type application/json
            if [ -f "$SITE_DIR/index.html" ]; then
              aws s3 cp "$SITE_DIR/index.html" "s3://$B/index.html" --cache-control "no-cache, no-store, must-revalidate" --content-type text/html
            fi
          done

          # Invalidate CloudFront so latest app shell is served and wait for completion
          DIST_ID='${{ steps.front.outputs.alias_dist_id }}'
          if [ -z "$DIST_ID" ] || [ "$DIST_ID" = "None" ]; then DIST_ID='${{ steps.front.outputs.dist_id }}'; fi
          if [ -n "$DIST_ID" ] && [ "$DIST_ID" != "None" ]; then
            INV_JSON=$(aws cloudfront create-invalidation --distribution-id "$DIST_ID" --paths \
              "/" \
              "/index.html" \
              "/app.js" \
              "/styles.css" \
              "/sw.js" \
              "/manifest.json" \
              "/manifest.webmanifest" \
              "/config.js" \
              "/app-version.js" \
              "/version.json" \
              "/icons/*")
            INV_ID=$(printf "%s" "$INV_JSON" | jq -r '.Invalidation.Id')
            if [ -n "$INV_ID" ] && [ "$INV_ID" != "null" ]; then
              echo "Waiting for CloudFront invalidation $INV_ID to complete ..."
              aws cloudfront wait invalidation-completed --distribution-id "$DIST_ID" --id "$INV_ID" || true
            fi
          else
            echo "Skipping CloudFront invalidation: no distribution id resolved." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Verify frontend homepage (apex and www, after invalidation, retry up to 5 min)
        id: verify1
        run: |
          set +e
          echo "Waiting for homepage(s) to return 200 (up to 5 minutes)..." >> $GITHUB_STEP_SUMMARY
          ATT=0; MAX=30; SLEEP=10; CODE_APEX="000"; CODE_WWW="skip"
          CHECK_WWW=false
          if [ "${INCLUDE_WWW}" = "true" ]; then CHECK_WWW=true; fi
          while [ $ATT -lt $MAX ]; do
            CODE_APEX=$(curl -s -o /dev/null -w "%{http_code}" "https://${DOMAIN_NAME}/" || echo 000)
            if $CHECK_WWW; then
              CODE_WWW=$(curl -s -o /dev/null -w "%{http_code}" "https://www.${DOMAIN_NAME}/" || echo 000)
            fi
            if [ "$CODE_APEX" = "200" ] && { ! $CHECK_WWW || [ "$CODE_WWW" = "200" ]; }; then
              break
            fi
            ATT=$((ATT+1))
            sleep $SLEEP
          done
          echo "Homepage https://${DOMAIN_NAME}/ status: ${CODE_APEX} after $ATT attempts" >> $GITHUB_STEP_SUMMARY
          if $CHECK_WWW; then echo "Homepage https://www.${DOMAIN_NAME}/ status: ${CODE_WWW} after $ATT attempts" >> $GITHUB_STEP_SUMMARY; fi
          NEED_RECOVERY="false"
          if [ "$CODE_APEX" != "200" ]; then NEED_RECOVERY="true"; fi
          if $CHECK_WWW && [ "$CODE_WWW" != "200" ]; then NEED_RECOVERY="true"; fi
          echo "code=${CODE_APEX}" >> "$GITHUB_OUTPUT"
          echo "code_www=${CODE_WWW}" >> "$GITHUB_OUTPUT"
          echo "need_recovery=${NEED_RECOVERY}" >> "$GITHUB_OUTPUT"
          set -e

      - name: "Recovery: resync to active CloudFront origin if homepage not 200"
        if: ${{ env.USE_CLOUDFRONT == 'true' && steps.verify1.outputs.need_recovery == 'true' }}
        run: |
          set -e
          echo "Attempting recovery: determine active CloudFront distribution by alias and resync" >> $GITHUB_STEP_SUMMARY
          # Ensure jq installed
          if ! command -v jq >/dev/null 2>&1; then sudo apt-get update -y && sudo apt-get install -y jq; fi

          # Find distribution that serves our DOMAIN_NAME alias
          DID=$(aws cloudfront list-distributions \
            --query "DistributionList.Items[?Aliases.Items!=null && (contains(Aliases.Items, '${DOMAIN_NAME}') || contains(Aliases.Items, 'www.${DOMAIN_NAME}'))].[Id,DomainName] | [0]" \
            --output text 2>/dev/null || true)
          if [ -z "$DID" ] || [ "$DID" = "None" ]; then
            echo "No existing CloudFront distribution found by alias. Skipping recovery." >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          CF_ID=$(echo "$DID" | awk '{print $1}')
          CF_DOM=$(echo "$DID" | awk '{print $2}')
          echo "Active distribution by alias: $CF_ID ($CF_DOM)" >> $GITHUB_STEP_SUMMARY

          # Resolve default origin bucket from distribution config
          DIST_JSON=$(aws cloudfront get-distribution --id "$CF_ID" --output json)
          TOID=$(echo "$DIST_JSON" | jq -r '.Distribution.DistributionConfig.DefaultCacheBehavior.TargetOriginId // empty')
          ODOM=$(echo "$DIST_JSON" | jq -r ".Distribution.DistributionConfig.Origins.Items[] | select(.Id==\"${TOID}\").DomainName // empty")
          if [ -z "$ODOM" ]; then
            echo "Could not resolve origin domain from distribution $CF_ID" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          BUCKET="$ODOM"
          BUCKET=$(echo "$BUCKET" | sed -E 's/\.s3(\.[a-z0-9-]+)?\.amazonaws\.com$//')
          echo "Resolved origin bucket for active distribution: $BUCKET (from $ODOM)" >> $GITHUB_STEP_SUMMARY

          # Stage entire frontend into a temporary dir
          SITE_DIR=$(mktemp -d)
          cp -R frontend/website/. "$SITE_DIR/"

          # Cache-bust references in index.html
          BUILD_ID="${GITHUB_RUN_ID:-0}-${GITHUB_RUN_ATTEMPT:-0}"
          if [ -f "$SITE_DIR/index.html" ]; then
            sed -i "s|\"app.js\"|\"app.js?v=${BUILD_ID}\"|g" "$SITE_DIR/index.html" || true
            sed -i "s|\"styles.css\"|\"styles.css?v=${BUILD_ID}\"|g" "$SITE_DIR/index.html" || true
            sed -i "s|\"manifest.webmanifest\"|\"manifest.webmanifest?v=${BUILD_ID}\"|g" "$SITE_DIR/index.html" || true
            sed -i "s|\"manifest.json\"|\"manifest.json?v=${BUILD_ID}\"|g" "$SITE_DIR/index.html" || true
            sed -i "s|\"config.js\"|\"config.js?v=${BUILD_ID}\"|g" "$SITE_DIR/index.html" || true
            sed -i "s|\"app-version.js\"|\"app-version.js?v=${BUILD_ID}\"|g" "$SITE_DIR/index.html" || true
          fi

          # Ensure runtime artifacts exist
          echo "window.APP_VERSION='${BUILD_ID}';" > "$SITE_DIR/app-version.js"
          if [ ! -f "$SITE_DIR/config.js" ]; then
            echo "window.RUNTIME_CONFIG=Object.assign({},window.RUNTIME_CONFIG||{},{BACKEND_URL:''});" > "$SITE_DIR/config.js"
          fi

          # Sync to resolved bucket and force no-cache on critical assets
          aws s3 sync "$SITE_DIR" "s3://$BUCKET" --delete
          aws s3 cp "$SITE_DIR/index.html" "s3://$BUCKET/index.html" --cache-control "no-cache, no-store, must-revalidate" --content-type text/html
          if [ -f "$SITE_DIR/sw.js" ]; then
            aws s3 cp "$SITE_DIR/sw.js" "s3://$BUCKET/sw.js" --cache-control "no-cache, no-store, must-revalidate" --content-type application/javascript
          fi
          aws s3 cp "$SITE_DIR/config.js" "s3://$BUCKET/config.js" --cache-control "no-cache, no-store, must-revalidate" --content-type application/javascript
          aws s3 cp "$SITE_DIR/app-version.js" "s3://$BUCKET/app-version.js" --cache-control "no-cache, no-store, must-revalidate" --content-type application/javascript

          # Invalidate and wait
          INV_JSON=$(aws cloudfront create-invalidation --distribution-id "$CF_ID" --paths "/" "/index.html" "/config.js" "/app-version.js" "/sw.js" 2>/dev/null || true)
          IID=$(echo "$INV_JSON" | jq -r '.Invalidation.Id // empty')
          if [ -n "$IID" ]; then
            echo "Waiting for recovery invalidation $IID to complete ..." >> $GITHUB_STEP_SUMMARY
            aws cloudfront wait invalidation-completed --distribution-id "$CF_ID" --id "$IID" || true
          fi

      - name: Verify frontend homepage after recovery (retry up to 5 min)
        if: steps.verify1.outputs.code != '200'
        run: |
          set +e
          echo "Re-checking homepage to return 200 (up to 5 minutes) after recovery..." >> $GITHUB_STEP_SUMMARY
          ATT=0; MAX=30; SLEEP=10; CODE="000"
          while [ $ATT -lt $MAX ]; do
            CODE=$(curl -s -o /dev/null -w "%{http_code}" "https://${DOMAIN_NAME}/" || echo 000)
            if [ "$CODE" = "200" ]; then
              break
            fi
            ATT=$((ATT+1))
            sleep $SLEEP
          done
          echo "Post-recovery homepage https://${DOMAIN_NAME}/ status: ${CODE} after $ATT attempts" >> $GITHUB_STEP_SUMMARY
          set -e

      - name: Compute AllowedOrigins for backend
        id: origins
        run: |
          CF_DOMAIN='${{ steps.front.outputs.cf_domain }}'
          AO="https://${DOMAIN_NAME}"
          if [ "${INCLUDE_WWW}" = "true" ]; then AO="$AO,https://www.${DOMAIN_NAME}"; fi
          if [ -n "$CF_DOMAIN" ] && [ "$CF_DOMAIN" != "None" ]; then AO="$AO,https://$CF_DOMAIN"; fi
          echo "allowed=$AO" >> "$GITHUB_OUTPUT"

      - name: Ensure helper scripts are executable
        run: |
          chmod +x infra/scripts/deploy-backend.sh || true
          chmod +x infra/scripts/link-frontend.sh || true
          chmod +x scripts/cors-test.sh || true
          chmod +x scripts/api-smoke.sh || true
          chmod +x scripts/check-backend.sh || true

      - name: Detect existing API DNS record
        run: |
          set -e
          API_FQDN="${API_SUBDOMAIN}.${DOMAIN_NAME}."
          API_A=$(aws route53 list-resource-record-sets \
            --hosted-zone-id "${HOSTED_ZONE_ID}" \
            --query "ResourceRecordSets[?Name=='${API_FQDN}'] | [?Type=='A' || Type=='AAAA'] | [0].Type" \
            --output text 2>/dev/null || true)
          if [ -n "$API_A" ] && [ "$API_A" != "None" ]; then
            echo "CREATE_API_DNS_RECORD=false" >> "$GITHUB_ENV"
            echo "Skipping API DNS record creation (record already exists for ${API_FQDN})." >> $GITHUB_STEP_SUMMARY
          else
            echo "CREATE_API_DNS_RECORD=true" >> "$GITHUB_ENV"
          fi

      - name: Choose API subdomain (auto if requested)
        run: |
          set -e
          AS="${API_SUBDOMAIN:-}"
          if [ -z "$AS" ] || [ "$AS" = "auto" ]; then
            AS="api-${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}"
            echo "API_SUBDOMAIN=$AS" >> "$GITHUB_ENV"
            echo "Auto-selected API subdomain: $AS" >> $GITHUB_STEP_SUMMARY
          else
            echo "Using API subdomain from vars: $AS" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Deploy backend stack (EC2 + Nginx TLS)
        run: |
          # Use repository URL (must be public for EC2 to clone)
          REPO_URL="${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}.git"
          # Pass CREATE_API_DNS_RECORD to the deploy script via environment
          export CREATE_API_DNS_RECORD="${CREATE_API_DNS_RECORD:-true}"
          ./infra/scripts/deploy-backend.sh \
            "${BACKEND_STACK_NAME}" \
            "${DOMAIN_NAME}" \
            "${HOSTED_ZONE_ID}" \
            "${VPC_ID}" \
            "${SUBNET_ID}" \
            "${{ steps.origins.outputs.allowed }}" \
            "${API_SUBDOMAIN}" \
            "$REPO_URL" \
            "${BACKEND_REGION}"

      - name: Ensure/repair API DNS record (UPSERT A -> EC2 PublicIp)
        run: |
          set -e
          BE_STACK="${BACKEND_STACK_NAME}"
          BE_REGION="${BACKEND_REGION}"
          API_FQDN=$(aws cloudformation describe-stacks \
            --region "$BE_REGION" \
            --stack-name "$BE_STACK" \
            --query "Stacks[0].Outputs[?OutputKey=='ApiDomainName'].OutputValue | [0]" \
            --output text)
          # Prefer live EC2 PublicIp to avoid any stale CFN output
          IID=$(aws cloudformation describe-stacks --region "$BE_REGION" --stack-name "$BE_STACK" --query "Stacks[0].Outputs[?OutputKey=='InstanceId'].OutputValue | [0]" --output text)
          PUBLIC_IP=$(aws ec2 describe-instances --region "$BE_REGION" --instance-ids "$IID" --query "Reservations[0].Instances[0].PublicIpAddress" --output text)
          if [ -z "$API_FQDN" ] || [ "$API_FQDN" = "None" ] || [ -z "$PUBLIC_IP" ] || [ "$PUBLIC_IP" = "None" ]; then
            echo "Skipping explicit DNS upsert (missing outputs)." >> $GITHUB_STEP_SUMMARY
          else
            CHANGE_FILE=$(mktemp)
            cat > "$CHANGE_FILE" <<JSON
          { "Comment": "UPSERT api record for TickTock backend", "Changes": [ { "Action": "UPSERT", "ResourceRecordSet": { "Name": "${API_FQDN}.", "Type": "A", "TTL": 60, "ResourceRecords": [ { "Value": "${PUBLIC_IP}" } ] } } ] }
          JSON
            CHG=$(aws route53 change-resource-record-sets --hosted-zone-id "${HOSTED_ZONE_ID}" --change-batch "file://$CHANGE_FILE")
            CID=$(echo "$CHG" | jq -r '.ChangeInfo.Id')
            echo "Route53 change submitted: $CID (api -> $PUBLIC_IP)" >> $GITHUB_STEP_SUMMARY
            aws route53 wait resource-record-sets-changed --id "$CID" || true
          fi

      - name: Wait for TCP 443 to open (up to 5 min)
        run: |
          set +e
          API_FQDN="${API_SUBDOMAIN}.${DOMAIN_NAME}"
          echo "Waiting for TCP 443 at ${API_FQDN} to accept connections ..." >> $GITHUB_STEP_SUMMARY
          ATT=0; MAX=150; SLEEP=2; OK=0
          while [ $ATT -lt $MAX ]; do
            (echo > /dev/tcp/${API_FQDN}/443) >/dev/null 2>&1 && { OK=1; break; }
            ATT=$((ATT+1)); sleep $SLEEP
          done
          if [ $OK -eq 1 ]; then
            echo "TCP 443 is open after $((ATT*SLEEP))s." >> $GITHUB_STEP_SUMMARY
          else
            echo "Warning: TCP 443 did not open within $((MAX*SLEEP/60)) min; continuing." >> $GITHUB_STEP_SUMMARY
          fi
          set -e


      - name: SSM nudge - ensure Nginx proxy is running and check ports
        run: |
          set -e
          IID=$(aws cloudformation describe-stacks \
            --region "${BACKEND_REGION}" \
            --stack-name "${BACKEND_STACK_NAME}" \
            --query "Stacks[0].Outputs[?OutputKey=='InstanceId'].OutputValue | [0]" \
            --output text)
          if [ -z "$IID" ] || [ "$IID" = "None" ]; then
            echo "No InstanceId resolved for SSM nudge." >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          echo "Sending SSM command to $IID to ensure Nginx is running..." >> $GITHUB_STEP_SUMMARY
          PARAMS_FILE=$(mktemp)
          APIDOM="${API_SUBDOMAIN}.${DOMAIN_NAME}"
          cat > "$PARAMS_FILE" <<JSON
          {
            "commands": [
              "set -e",
              "cd /opt/ticktock || cd /",
              "echo --- export APIDOM/DOMAIN ---",
              "export APIDOM=${APIDOM}",
              "export API_SUBDOMAIN=${API_SUBDOMAIN}",
              "export DOMAIN_NAME=${DOMAIN_NAME}",
              "echo --- pull repo ---",
              "if [ -d /opt/ticktock/.git ]; then git -C /opt/ticktock fetch --all --prune || true; git -C /opt/ticktock reset --hard origin/main || true; git -C /opt/ticktock clean -fd -e .env || true; fi",
              "echo --- run nudge - nginx ---",
              "bash /opt/ticktock/scripts/ssm-nudge.sh",
              "echo --- docker ps ---",
              "docker ps --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}' || true",
              "echo --- sockets ---",
              "ss -ltnp | egrep ':(80|443|8080|8443)' || true",
              "echo --- nginx via localhost test ---",
              "curl -sk --max-time 8 -H 'Host: ${APIDOM}' http://127.0.0.1/healthz || true",
              "echo --- nginx logs last 120 ---",
              "docker logs --tail=120 ttt-nginx 2>&1 || true",
              "echo --- backend logs last 120 ---",
              "docker logs --tail=120 ttt-backend 2>&1 || true",
              "echo --- localhost backend health http://localhost:8080/healthz ---",
              "curl -sS --max-time 6 http://localhost:8080/healthz || true"
            ]
          }
          JSON
          CMD_ID=$(aws ssm send-command \
            --region "${BACKEND_REGION}" \
            --instance-ids "$IID" \
            --document-name "AWS-RunShellScript" \
            --parameters file://$PARAMS_FILE \
            --query "Command.CommandId" --output text)
          # give it a bit more time to complete
          sleep 20
          OUT=$(aws ssm get-command-invocation --region "${BACKEND_REGION}" --command-id "$CMD_ID" --instance-id "$IID" --query "StandardOutputContent" --output text || true)
          ERR=$(aws ssm get-command-invocation --region "${BACKEND_REGION}" --command-id "$CMD_ID" --instance-id "$IID" --query "StandardErrorContent" --output text || true)
          echo "\nSSM output (docker/ports/logs):\n${OUT}" >> $GITHUB_STEP_SUMMARY || true
          echo "\nSSM stderr (if any):\n${ERR}" >> $GITHUB_STEP_SUMMARY || true
          # Also print to raw logs for easier debugging
          echo "===== BEGIN SSM OUTPUT ====="
          echo "$OUT"
          echo "===== END SSM OUTPUT ====="
          if [ -n "$ERR" ] && [ "$ERR" != "None" ]; then
            echo "===== BEGIN SSM STDERR ====="
            echo "$ERR"
            echo "===== END SSM STDERR ====="
          fi

      - name: Verify DNS resolution and HTTPS health for API
        run: |
          set -e
          API_FQDN="${API_SUBDOMAIN}.${DOMAIN_NAME}"
          if ! command -v dig >/dev/null 2>&1; then sudo apt-get update -y && sudo apt-get install -y dnsutils; fi
          echo "DNS check for ${API_FQDN}" >> $GITHUB_STEP_SUMMARY
          RES=$(dig +short "${API_FQDN}")
          echo "dig +short ${API_FQDN} -> ${RES}" >> $GITHUB_STEP_SUMMARY
          HC=$(curl -sk -o /dev/null -w "%{http_code}" "https://${API_FQDN}/healthz" || true)
          echo "HTTPS /healthz status: ${HC}" >> $GITHUB_STEP_SUMMARY

      - name: Wait for backend health (retry up to 3 min)
        run: |
          set +e
          BE_URL=$(aws cloudformation describe-stacks \
            --region "${BACKEND_REGION}" \
            --stack-name "${BACKEND_STACK_NAME}" \
            --query "Stacks[0].Outputs[?OutputKey=='BackendEndpoint'].OutputValue | [0]" \
            --output text)
          if [ -z "$BE_URL" ] || [ "$BE_URL" = "None" ]; then
            echo "No backend endpoint resolved for retry health check." >> $GITHUB_STEP_SUMMARY
          else
            echo "Waiting for backend to become healthy at $BE_URL ..." >> $GITHUB_STEP_SUMMARY
            ATTEMPTS=0; MAX_ATTEMPTS=12; SLEEP=15
            OK=0
            while [ $ATTEMPTS -lt $MAX_ATTEMPTS ]; do
              CODE=$(curl -sk -o /dev/null -w "%{http_code}" "$BE_URL/healthz" || echo "000")
              if [ "$CODE" = "200" ]; then OK=1; break; fi
              ATTEMPTS=$((ATTEMPTS+1))
              sleep $SLEEP
            done
            if [ $OK -eq 1 ]; then
              echo "Backend healthy (HTTP 200 on /healthz) after $ATTEMPTS attempts." >> $GITHUB_STEP_SUMMARY
            else
              echo "Backend still not healthy after $((MAX_ATTEMPTS*SLEEP/60)) minutes. Proceeding but marking as warning." >> $GITHUB_STEP_SUMMARY
            fi
          fi
          set -e

      - name: Link frontend to backend endpoint (write config.js)
        run: |
          BACKEND_OVERRIDE_URL="${BACKEND_OVERRIDE_URL}" USE_RELATIVE_API="${USE_RELATIVE_API}" \
          ./infra/scripts/link-frontend.sh "${FRONTEND_STACK_NAME}" "${BACKEND_STACK_NAME}" "${FRONTEND_REGION}" "${BACKEND_REGION}"

      - name: Smoke test backend CORS/health
        run: |
          set +e
          BE_URL=$(aws cloudformation describe-stacks \
            --region "${BACKEND_REGION}" \
            --stack-name "${BACKEND_STACK_NAME}" \
            --query "Stacks[0].Outputs[?OutputKey=='BackendEndpoint'].OutputValue | [0]" \
            --output text)
          echo "Testing backend: ${BE_URL} from origin https://${DOMAIN_NAME}" >> $GITHUB_STEP_SUMMARY
          if [ -n "$BE_URL" ] && [ "$BE_URL" != "None" ]; then
            scripts/cors-test.sh "$BE_URL" "https://${DOMAIN_NAME}" | sed -n '1,60p' >> $GITHUB_STEP_SUMMARY || true
          else
            echo "Warning: Backend endpoint could not be resolved for smoke test." >> $GITHUB_STEP_SUMMARY
          fi
          set -e

      - name: API smoke test (register/login/tasks)
        run: |
          set +e
          BE_URL=$(aws cloudformation describe-stacks \
            --region "${BACKEND_REGION}" \
            --stack-name "${BACKEND_STACK_NAME}" \
            --query "Stacks[0].Outputs[?OutputKey=='BackendEndpoint'].OutputValue | [0]" \
            --output text)
          if [ -n "$BE_URL" ] && [ "$BE_URL" != "None" ]; then
            echo "API smoke test against ${BE_URL}" >> $GITHUB_STEP_SUMMARY
            scripts/api-smoke.sh "$BE_URL" | sed -n '1,200p' >> $GITHUB_STEP_SUMMARY || true
          else
            echo "Skipping API smoke test: no backend endpoint resolved." >> $GITHUB_STEP_SUMMARY
          fi
          set -e

      - name: Publish smoke test outputs to CloudWatch Logs
        run: |
          set +e
          BE_URL=$(aws cloudformation describe-stacks \
            --region "${BACKEND_REGION}" \
            --stack-name "${BACKEND_STACK_NAME}" \
            --query "Stacks[0].Outputs[?OutputKey=='BackendEndpoint'].OutputValue | [0]" \
            --output text)
          LOG_GROUP="/TickTock/Backend-${DOMAIN_NAME}"
          LOG_STREAM="ci-${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}"
          TMP_DIR=$(mktemp -d)
          CORS_OUT="$TMP_DIR/cors.txt"
          API_OUT="$TMP_DIR/api.txt"
          if [ -n "$BE_URL" ] && [ "$BE_URL" != "None" ]; then
            scripts/cors-test.sh "$BE_URL" "https://${DOMAIN_NAME}" > "$CORS_OUT" 2>&1 || true
            scripts/api-smoke.sh "$BE_URL" > "$API_OUT" 2>&1 || true
          else
            echo "No backend endpoint resolved for smoke logs." > "$CORS_OUT"
            : > "$API_OUT"
          fi
          # Ensure log group/stream exist in backend region
          aws logs create-log-group --region "${BACKEND_REGION}" --log-group-name "$LOG_GROUP" >/dev/null 2>&1 || true
          aws logs create-log-stream --region "${BACKEND_REGION}" --log-group-name "$LOG_GROUP" --log-stream-name "$LOG_STREAM" >/dev/null 2>&1 || true
          SEQ=$(aws logs describe-log-streams --region "${BACKEND_REGION}" --log-group-name "$LOG_GROUP" --log-stream-name-prefix "$LOG_STREAM" --query "logStreams[0].uploadSequenceToken" --output text 2>/dev/null)
          TS=$(date +%s%3N)
          MSG1="CI CORS/health smoke for ${BE_URL} from https://${DOMAIN_NAME}\\n$(sed -n '1,200p' "$CORS_OUT")"
          MSG2="CI API smoke for ${BE_URL}\\n$(sed -n '1,200p' "$API_OUT")"
          if [ -n "$SEQ" ] && [ "$SEQ" != "None" ]; then
            aws logs put-log-events --region "${BACKEND_REGION}" --log-group-name "$LOG_GROUP" --log-stream-name "$LOG_STREAM" --sequence-token "$SEQ" --log-events timestamp=$TS,message="$MSG1" timestamp=$((TS+1)),message="$MSG2" >/dev/null 2>&1 || true
          else
            aws logs put-log-events --region "${BACKEND_REGION}" --log-group-name "$LOG_GROUP" --log-stream-name "$LOG_STREAM" --log-events timestamp=$TS,message="$MSG1" timestamp=$((TS+1)),message="$MSG2" >/dev/null 2>&1 || true
          fi
          set -e

      - name: Output Summary
        run: |
          if [ "${USE_CLOUDFRONT}" = "true" ]; then
            echo "Frontend Bucket: ${{ steps.front.outputs.bucket }}" >> $GITHUB_STEP_SUMMARY
            echo "CloudFront ID: ${{ steps.front.outputs.dist_id }}" >> $GITHUB_STEP_SUMMARY
            echo "CloudFront Domain: ${{ steps.front.outputs.cf_domain }}" >> $GITHUB_STEP_SUMMARY
          fi
          echo "Allowed Origins: ${{ steps.origins.outputs.allowed }}" >> $GITHUB_STEP_SUMMARY
          BE_URL=$(aws cloudformation describe-stacks \
            --region "${BACKEND_REGION}" \
            --stack-name "${BACKEND_STACK_NAME}" \
            --query "Stacks[0].Outputs[?OutputKey=='BackendEndpoint'].OutputValue | [0]" \
            --output text)
          echo "Backend Endpoint: ${BE_URL}" >> $GITHUB_STEP_SUMMARY
